---
title: "Naive Bayes Model"

header-includes:
 - \usepackage{color} 
 - \definecolor{SolutionColor}{rgb}{0.1,0.1,0.1}
output: html_document
---
```{r}
###############################################################################
# Please replace all the author names in this file to make sure you produce the right result, there are total 4 need to be replaced.

# For example, if you want to test the result of "AKumar", then in the forth chunk you need to replace all "MMiller" to "AKumar". You can use Control+F and Replace ALl to make things easier.
###############################################################################
```

###Load required libraries and the original dataset
```{r loading libraryies and Data, echo=TRUE}
library(dplyr)
library(plyr)
library(parallel)
load("../data/Data.RData")
```

```{r load function}
source("../lib/Naive_A1_df.r")
source("../lib/Predict_model_A1.r")
source("../lib/get_train_test.r")
source("../lib/Log_A1_Value.r")
source("../lib/get_F1_accu.r")
source("../lib/dataclean.r")
source("../lib/dataprocess.r")
source("../lib/testclean.r")
source("../lib/testprocess.r")
source("../lib/get_F1.r")
source("../lib/get_GoldStand.r")
source("../lib/get_F1_accu.r")
source("../lib/dataclean3.r")
source("../lib/dataprocess3.r")

```

### Generate trainset and testset, random split the data into half and half in each group, each group here means each identity author ID.
```{r Generate trainset and test set}
set.seed(200)
train<- get_train_test(Data$MMiller.txt)[[1]]
test<-get_train_test(Data$MMiller.txt)[[2]]
```

# Naive Bayes Model

We assume that each author's citation data is generated by the naive Bayes model, and use his/her past citations as the training data to estimate the model parameters. Based on the parameter estimates, we use the Bayes rule to calculate the probability that each name entry $X_i(i\in [1,N])$, where $N$ is the total number of candidate name entries in the citation database) would have generated the input citation.\par

Given an input test citation $C$ with the omission of the query author, the target function is to find a name entry Xi in the citation database with the maximal posterior probability of producing the citation $C$, i.e.,

\begin{equation}
max_iP(x_i | C)
\end{equation}

Using the Bayes rule, the problem becomes finding

\begin{equation}
max_iP(x_i | C) = max_iP(C | X_i)P(X_i)/P(C)
\end{equation}

where $P(X_i)$ denotes the prior probability of Xi authoring papers, and is estimated from the training data as the proportion of the papers of $X_i$ among all the citations. 
\begin{equation}
P(X_i) = \frac{\text{# papers of $X_i$}}{\text{# all citations}}
\end{equation}
$P(C)$ denotes the probability of the citation C and is omitted since it does not depend on Xi. Then Function 2 becomes
\begin{equation}
P(C|X_i)=\prod_{j}P(A_j|X_i) = \prod_{j}\prod_{k}P(A_{jk}|X_i)
\end{equation}

where $A_j$ denotes the different type of attribute; that is, $A_1$ - the coauthor names; $A_2$ - the paper title; $A_3$ - the journal title. Each attribute is decomposed into independent elements represented by $A_{jk}$ $(k \in [0..K(j)])$. $K(j)$ is the total number of elements in attribute $A_j$.

To avoid underflow, we store log probabilities in our implementation, and the target function becomes:

\begin{equation}
max_iP(X_i|C)=max_i[\sum_{j}\sum_{k}\log(P(A_{jk}|X_i))+\log(P(X_i))]
\end{equation}

where $j\in[1,3]$ and $k\in[0,K(j)]$.

# Model parameters and Estimation

###Decomposition and estimation of the coauthor conditional probability $P(A_1|X_i)$
From the training citations, we calculate the following conditional probabilities.

$P(N|X_i)$ -the probability of $X_i$ writing a future paper alone conditioned on the event of $X_i$, estimated as the proportion of the papers that $X_i$ authors alone among all the papers of $X_i$. (N stands for "No coauthor", and "Co" below stands for "Has coauthor").
\begin{equation}
P(N|X_i) = \frac{\text{# of papers $X_i$ authors alone}}{\text{# of all the paper of $X_i$}}
\end{equation}

$P(Co|Xi)$ - the probability of $X_i$ writing a future paper with coauthors conditioned on the event of $X_i$.
\begin{equation}
P(Co|X_i) = 1-P(N|X_i)
\end{equation}

$P(Seen|Co,X_i)$ - the probability of $X_i$ writing a future paper with previously seen coauthors conditioned on the event that $X_i$ writes a future paper with coauthors. We regard the coauthors coauthoring a paper with $X_i$ at least twice in the training citations as the "seen coauthors"; the other coauthors coauthoring a paper with $X_i$ only once in the training citations is considered as the "unseen coauthors". Therefore, we estimate $P(Seen|Co,X_i)$ as the proportion of the number of times that $X_i$ coauthors with "seen coauthors" among the total number of times that $X_i$ coauthors with any coauthor. Note that if $X_i$ has n coauthors in a training citation $C$, we count that $X_i$ coauthors $n$ times in citation $C$.
\begin{equation}
P(Seen|Co,X_i) = \frac{\text{# of times $X_i$ coauthors with seen coauthors}}{\text{# of times $X_i$ coauthors with any coauthor}}
\end{equation}

$P(Unseen|Co,X_i)$ the probability of $X_i$ writing a future paper with "unseen coauthors" conditioned on the event that $X_i$ writes a paper with coauthors.
\begin{equation}
P(Unseen|Co,X_i) =1-P(Seen|Co,X_i)
\end{equation}

$P(A_{1k}|Seen,Co,X_i)$ - the probability of $X_i$ writing a future paper with a particular coauthor $A_{1k}$ conditioned on the event that $X_i$ writes a paper with previously seen coauthors. We estimate it as the proportion of the number of times that $X_i$ coauthors with $A_{1k}$ among the total number of times $X_i$ coauthors with any coauthor.
\begin{equation}
P(A1k|Seen,Co,X_i)=\frac{\text{# of times $X_i$ coauthors with $A_{1k}$}}{\text{# of times $X_i$ coauthors with seen coauthors}}
\end{equation}

$P(A_{1k}|Unseen,Co,X_i)$ - the probability of Xi writing a future paper with a particular coauthor $A_{1k}$ conditioned on the event that $X_i$ writes a paper with unseen coauthors. Considering all the names in the training citations as the population and assuming that $X_i$ has equal probability to coauthor with an unseen author, we estimate $P(A_{1k}|Unseen,Co,X_i)$ as 1 divided by the total number of author (or coauthor) names in the training citations minus the number of coauthors of {X_i}.
\begin{equation}
P(A_{1k}|Unseen,Co,X_i)=\frac{1}{\text{# of all authors}+\text{# of coauthors of $X_i$}}
\end{equation}

####1. Cleaning Data for A1(Coauthor)
Based on above, creat a Data Frame $Author Data$ which includes coauthors names, author ID, and number of times the author coauthors with this specific coauthor. In addition, in this dataframe we include the $P(Co|X_i)$, $P(Seen | CO, X_i)$, $P(Unseen | Co, X_i)$, and the number of times $X_i$ coauthors with any seen coauthor. 
```{r Creat a A1 dictionary based on trainset, warning=FALSE}
# Extract the second column and the fifth column which are the coauthor and author ID
train1<-train[,c(2,5)]
test1<-test[,c(2,5)]
a_train<-tapply(train1$Coauthor,train1$AuthorID,strsplit,split=";")
#a_train<-subset(a_train,llply(a_train, length) != 1)
#class(a_train)

# Create a dataframe of author DJohnson

# number of indentity authors
n<-length(a_train)

Author_data<-data.frame()
for(i in 1:n){
  author<-df(a_train[[i]])
  author$author_id<-i
  Author_data<-rbind(Author_data,author)
}

# Remove author him/herself
Author_data<-Author_data[which(Author_data$Var1 != "MMiller"),]
# Remove blanket
Author_data<-Author_data[which(Author_data$Var1 != ""),]

# Number of existing author ID, since maybe one author id just has one paper and doesn't have any coauthor
exist_author_id<-unique(Author_data$author_id)

m<-length(unique(Author_data$author_id))
```

####2. Generate a dictionary for A1(Coauthor)
Here we calculate the 5 probabilities based the above dataframe. 
```{r}
# What we need to compute is prob_A1k_seencoxi
# Creat a dataframe seen_df which shows number of times xi coauthors with A1k
seen_df<-as.data.frame(matrix(NA,ncol = nrow(Author_data),nrow = m))
colnames(seen_df)<-Author_data$Var1

for (i in 1:m){
  for (j in 1: nrow(Author_data)){
    seen_df[i,j]<-ifelse(Author_data$author_id[j] == exist_author_id[i],
                         Author_data$numer_xi_seen_coau[j],0)}}

unique_coauthor<-unique(colnames(seen_df))
SEEN_DF<-matrix(NA, nrow = m,ncol = length(unique_coauthor))
colnames(SEEN_DF)<-unique_coauthor

for(i in 1:length(unique_coauthor)){
  
  logical_v<-colnames(seen_df) == unique_coauthor[i]
  
  if(sum(logical_v)>1){
    SEEN_DF[,i]<-rowSums(seen_df[,colnames(seen_df) == i])
  }else{
    SEEN_DF[,i]<-seen_df[,logical_v]
  }
}

# number of times xi coauthors with any seen coauthors
nxi_seen<-tapply(Author_data$numer_xi_seen_coau,Author_data$author_id,sum)

# p(seen | co,xi)
p_seen_coxi<-as.numeric(tapply(Author_data$prob_seen_cox1,Author_data$author_id,unique))
#p_seen_coxi[which(is.na(p_seen_coxi)|p_seen_coxi == Inf|p_seen_coxi == -Inf)]<-1

# p(co | xi)
p_co_xi<-as.numeric(tapply(Author_data$prob_cox1,Author_data$author_id,unique))

# p(unseen|co,xi)
p_unseen_coxi<-as.numeric(tapply(Author_data$prob_unseen_cox1,Author_data$author_id,unique))
#p_unseen_coxi[which(is.na(p_unseen_coxi)|p_unseen_coxi == Inf|p_unseen_coxi == -Inf)]<-0

# number of all authors and coauthors
all_a_c<-length(unique(Author_data$Var1))+n

# number of coauthors of xi
number_coa_xi<-rep(NA, m)
for(i in 1:m){
  number_coa_xi[i]<-nrow(Author_data[Author_data$author_id == exist_author_id[i],])
}

# p(A1k|unseen,co,xi)
p_A1k_unseencoxi<-1/(all_a_c - number_coa_xi)

# The first seen term
seen_term<-p_seen_coxi*p_co_xi

# The second term of object function p(A1k|unseen,co,xi)*p(unseen|co,xi)*p(co | xi) becomes
unseen_term<-p_A1k_unseencoxi*p_unseen_coxi*p_co_xi

# p(xi)
count_xi<-as.numeric(table(train1$AuthorID))
p_xi<-count_xi/sum(count_xi)

# P(N|xi)
P_N_xi<-c()
for(i in 1:length(unique(train1$AuthorID))){
  xi<-subset(train1, AuthorID == i)
    l<-laply(laply(xi$Coauthor,strsplit,";"), length)
    P_N_xi[i]<-sum(l == 1)/length(l)}
```

Given a citation, which only include the coauthors names, we can predict the author ID based on Naive Bayes approch. First, we need to see if the given citation has any coauthor, if no, we say that the $P(A_1|X_i) = P(N|X_i)$, otherwise we calculate $P(A_{1k}|X_i) = P(A_{11}|X_i)...P(A_{1K}|X_{i})$, where

\begin{equation}
P(A_{1k}|X_i) = P(A_{1k},N|X_i)+P(A_{1k},Co|X_i) = 0+P(A_{1k},Co|X_i)=P(A_{1k}|Seen,Co,X_i)+P(A_{1k}|Unseen,Co,X_i) \\
=P(A_{1k}|Seen,Co,X_i)*P(Seen|Co,X_i)*P(Co|X_i)+P(A_{1k}|Unseen,Co,X_i)*P(Unseen|Co,X_i)*P(Co|X_i)
\end{equation}


####3. Predict label when using A1(Coauthor) only
Calculate the object function $P(X_i|C)$, we find the one with the largest value which is our predict author ID.
```{r Model output label, warning=FALSE}
# Generate prediction label when use A1(coauthor feature) only
predict_label<-rep(NA, nrow(test1))
#predict_label<-c()
for(i in 1:nrow(test1)){
  predict_label[i]<-citation_A1(test1[i,1],"MMiller")}
#predict_label

predict_label<-as.numeric(predict_label)
predict_label
```

###Decomposition and estimation of the coauthor conditional probability $P(A_2|X_i)$ and $P(A_3|X_i)$
Different from A_1, the other two features, the paper title and the journal title can be dealt with the same way but a little shorter. That is because you don't need to cae about such situation like "no title", we justneed to focus the appearance of the key words to find the probability.

\begin{equation}
P(A2k|X_i)=\frac{\text{# of times $X_i$ uses $A_{2k}$}}{\text{total # of times $A_{2k}$ was ever used}}
\end{equation}

\begin{equation}
P(A3k|X_i)=\frac{\text{# of times $X_i$ uses $A_{3k}$}}{\text{total # of times $A_{3k}$ was ever used}}
\end{equation}

What we're doing means that is we were given a test word, we can look up in our database to find the words used by different authors, and we supposed to believe that the words belongs to the author who used it most frequently.

Here we calculate the probabilities based on our trained dataset.

####1.First clean the data and create a dictionary for A3(Journal title)
```{r}

create_data <- function(filename){
  #name <- deparse(substitute(filename))
  tmp <- read.csv(filename,
                  header = F,
                  sep = "\n")    
  rule = "<([[:alpha:]]|[[:punct:]]){1,4}>"
  tmp$V1 = gsub(rule,"",tmp$V1)
  rule1 = ">([[:alpha:]]){1,5}:"
  tmp$V1 = gsub(rule1,">",tmp$V1)
  Sys.setlocale('LC_ALL','C')
  L = strsplit(tmp$V1,split = ">")
  tmp$Coauthor = laply(L,function(t) t[1])
  tmp$Paper = laply(L,function(t) t[2])
  tmp$Journal = laply(L,function(t) t[3])
  
  # extract canonical author id befor "_"
  tmp$AuthorID <- as.numeric(sub("_.*","",tmp$Coauthor))
  # extract paper number under same author between "_" and first whitespace
  tmp$PaperNO <- as.numeric(sub(".*_(\\w*)\\s.*", "\\1", tmp$Coauthor))
  # delete "<" in AKumar$Coauthor, you may need to further process the coauthor
  # term depending on the method you are using
  tmp$Coauthor <- gsub("<","",sub("^.*?\\s","", tmp$Coauthor))
  # delete "<" in AKumar$Paper
  tmp$Paper <- gsub("<","",tmp$Paper)
  # add PaperID for furthur use, you may want to combine all the nameset files and 
  # then assign the unique ID for all the citations
  tmp$PaperID <- rownames(tmp)
  tmp = tmp[,-1]
  return(tmp)
}
setwd("../data/nameset")
file_names <- list.files(pattern = "*.txt")
#file_names = file_names[-c(6,7,10)]
Data1 = list()
for(i in 1:length(file_names)){
  Data1[[i]]= create_data(file_names[i])
}
names(Data1) = file_names

#Input matrix
train3<-train[,-1]
train3<-dataprocess3(train3)
test3<-test[,-1]
test3<-dataprocess3(test3)
temp<-dataclean3(train3)
```

####2.Compute the probabilities mentioned above:
```{r}
#total number of words
temp.num<-NULL
for(i in 1:nrow(temp)){
  temp.num<-paste(temp.num,temp$Title[i],sep = " ")
}
temp.num<-unlist(strsplit(temp.num,split = "\\s{1,10}"))
countnum<-length(unique(temp.num))
temp.num<-unique(temp.num)[-1]

#Output
Fun13  =  function(word){adply(temp[,2],1,function(t) sum(word == unlist(strsplit(t,split = " "))))[,2]}
final = apply(as.matrix(temp.num),1,Fun13)
denom = matrix(rep(colSums(final),nrow(temp)),nrow = nrow(temp),byrow = T)
final = final/denom
colnames(final)<-temp.num
```
We can look up in the above constructed dictionary whenever we were given a test data.

####3. Generate prediction label for A3
```{r Model output label2, warning=FALSE}
testtemp<-testclean(test3)
paper<-NULL
for(i in 1:nrow(test3)){
  paper[i]<-strsplit(testtemp$Title[i],split = "\\s{1,3}" )
}
paper<-f3(paper)
pred_label3<-judgement(paper)
pred_label3
```

###The A2 procedure is same as A3
####1. Create a dictionary for A2
```{r}
#Input matrix
train2<-train[,-1]
train2<-dataprocess(train2)
test2<-test[,-1]
test2<-dataprocess(test2)
temp<-dataclean(train2)

#total number of words
temp.num<-NULL
for(i in 1:nrow(temp)){
  temp.num<-paste(temp.num,temp$Title[i],sep = " ")
}
temp.num<-unlist(strsplit(temp.num,split = "\\s{1,10}"))
countnum<-length(unique(temp.num))
temp.num<-unique(temp.num)[-1]

#Output
Fun13  =  function(word){adply(temp[,2],1,function(t) sum(word == unlist(strsplit(t,split = " "))))[,2]}
final = apply(as.matrix(temp.num),1,Fun13)
denom = matrix(rep(colSums(final),nrow(temp)),nrow = nrow(temp),byrow = T)
final = final/denom
colnames(final)<-temp.num
```

####3. Generate prediction label for A2
```{r Model output label3, warning=FALSE}
testtemp<-testclean(test2)
paper<-NULL
for(i in 1:nrow(test2)){
  paper[i]<-strsplit(testtemp$Title[i],split = "\\s{1,3}" )
}
paper<-f3(paper)
pred_label2<-judgement(paper)
pred_label2
```


### Get F1 Score and accuracy for A1,A2,A3
F1 score and accuracy for A1
```{r}
#source("../lib/get_GoldStand.r")
#source("../lib/get_F1.r")

new_mydata<-data.frame(test1[,2],test1[,1])
colnames(new_mydata)<-c("AuthorID", "coauthor")
#View(new_mydata)
GoldStand<-get_GoldStand(new_mydata)
#F1<-rep(NA,12)
get_F1_accu(predict_label,new_mydata,GoldStand$a_c,GoldStand$b_d)
```

F1 score and accuracy for A3
```{r}
new_mydata<-data.frame(test3[,3],test3[,2])
colnames(new_mydata)<-c("AuthorID","papertitle")
GoldStand<-get_GoldStand(new_mydata)
F1<-get_F1_accu(pred_label3,new_mydata,GoldStand$a_c,GoldStand$b_d)
F1
```

F1 score and accuracy for A2
```{r}
new_mydata<-data.frame(test2[,3],test2[,2])
colnames(new_mydata)<-c("AuthorID","papertitle")
GoldStand<-get_GoldStand(new_mydata)
F1<-get_F1_accu(pred_label2,new_mydata,GoldStand$a_c,GoldStand$b_d)
F1
```